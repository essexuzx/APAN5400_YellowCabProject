{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601a4536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åˆ›å»ºè¡¨ yellow_taxi_clean ===\n",
      "âœ… Table yellow_taxi_clean created\n",
      "\n",
      "=== å¼€å§‹å¯¼å…¥æ•°æ®ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰===\n",
      "Loading cleaned data from yellow_taxi_2022_2025_final_cleaned.parquet\n",
      "âš ï¸  æµ‹è¯•æ¨¡å¼: ä»…å¯¼å…¥å‰ 1,000,000 è¡Œ\n",
      "Loaded parquet in 42.2s - Shape: (1000000, 17)\n",
      "Data prep completed in 4.2s - Rows to insert: 1,000,000\n",
      "CSV buffer created in 5.6s\n",
      "âœ… Inserted 1,000,000 rows in 3.8s (266,488 rows/sec)\n",
      "Total time: 55.8s\n",
      "\n",
      "=== éªŒè¯å¯¼å…¥ç»“æœ ===\n",
      "è¡¨ä¸­æ€»è®°å½•æ•°: 1,000,000\n",
      "æ—¶é—´èŒƒå›´: 2022-10-01 00:00:00 ~ 2022-10-10 22:45:44\n",
      "NULLå€¼ç»Ÿè®¡: passenger=0, distance=0, fare=0\n",
      "\n",
      "å‰5æ¡è®°å½•:\n",
      "(2, datetime.datetime(2022, 10, 1, 0, 0), datetime.datetime(2022, 10, 1, 0, 18, 21), 1, Decimal('9.06'), 1, 138, 107, 1, Decimal('26.5'), Decimal('0.5'), Decimal('0.5'), Decimal('6.0'), Decimal('6.55'), Decimal('0.3'), Decimal('44.1'), Decimal('2.5'))\n",
      "(2, datetime.datetime(2022, 10, 1, 0, 0), datetime.datetime(2022, 10, 1, 0, 10, 30), 1, Decimal('2.28'), 1, 164, 237, 1, Decimal('9.5'), Decimal('0.5'), Decimal('0.5'), Decimal('2.66'), Decimal('0.0'), Decimal('0.3'), Decimal('15.96'), Decimal('2.5'))\n",
      "(1, datetime.datetime(2022, 10, 1, 0, 0), datetime.datetime(2022, 10, 1, 0, 18, 42), 1, Decimal('2.6'), 1, 114, 79, 1, Decimal('13.5'), Decimal('3.0'), Decimal('0.5'), Decimal('3.45'), Decimal('0.0'), Decimal('0.3'), Decimal('20.75'), Decimal('2.5'))\n",
      "(2, datetime.datetime(2022, 10, 1, 0, 0, 1), datetime.datetime(2022, 10, 1, 0, 8, 56), 1, Decimal('1.03'), 1, 113, 148, 1, Decimal('7.5'), Decimal('0.5'), Decimal('0.5'), Decimal('3.39'), Decimal('0.0'), Decimal('0.3'), Decimal('14.69'), Decimal('2.5'))\n",
      "(2, datetime.datetime(2022, 10, 1, 0, 0, 1), datetime.datetime(2022, 10, 1, 0, 3, 56), 1, Decimal('1.47'), 1, 239, 151, 1, Decimal('6.0'), Decimal('0.5'), Decimal('0.5'), Decimal('2.45'), Decimal('0.0'), Decimal('0.3'), Decimal('12.25'), Decimal('2.5'))\n",
      "\n",
      "âœ… å¯¼å…¥å®Œæˆï¼\n",
      "\n",
      "ğŸ’¡ æç¤º: æµ‹è¯•å®Œæˆåï¼Œå¦‚éœ€å¯¼å…¥å…¨éƒ¨æ•°æ®ï¼Œè¯·å°† max_rows=100000 æ”¹ä¸º max_rows=None\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "import time\n",
    "\n",
    "# æ•°æ®åº“é…ç½®\n",
    "PG_HOST = \"localhost\"\n",
    "PG_PORT = 5432\n",
    "PG_DB   = \"taxi\"\n",
    "PG_USER = \"postgres\"\n",
    "PG_PASS = \"123\"\n",
    "\n",
    "def load_cleaned_parquet_to_postgres(path, max_rows=100000):\n",
    "    \"\"\"\n",
    "    æŠŠæ¸…æ´—å¥½çš„ yellow_taxi parquet æ–‡ä»¶\n",
    "    å¿«é€Ÿæ‰¹é‡å¯¼å…¥åˆ° PostgreSQL è¡¨ yellow_taxi_clean\n",
    "    \n",
    "    å‚æ•°:\n",
    "        path: parquet æ–‡ä»¶è·¯å¾„\n",
    "        max_rows: æœ€å¤§å¯¼å…¥è¡Œæ•°ï¼ŒNone è¡¨ç¤ºå¯¼å…¥å…¨éƒ¨æ•°æ®\n",
    "    \"\"\"\n",
    "    print(f\"Loading cleaned data from {path}\")\n",
    "    if max_rows:\n",
    "        print(f\"âš ï¸  æµ‹è¯•æ¨¡å¼: ä»…å¯¼å…¥å‰ {max_rows:,} è¡Œ\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. è¯»å– parquetï¼ˆæ·»åŠ  max_rows é™åˆ¶ï¼‰\n",
    "    df = pd.read_parquet(path, engine=\"pyarrow\")\n",
    "    if max_rows:\n",
    "        df = df.head(max_rows)\n",
    "    \n",
    "    load_time = time.time() - start_time\n",
    "    print(f\"Loaded parquet in {load_time:.1f}s - Shape: {df.shape}\")\n",
    "\n",
    "    # 2. åˆ—åç»Ÿä¸€æˆå°å†™ï¼Œæ–¹ä¾¿å¯¹é½ SQL\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "    # 3. ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime ç±»å‹\n",
    "    if \"tpep_pickup_datetime\" in df.columns:\n",
    "        df[\"tpep_pickup_datetime\"] = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "    if \"tpep_dropoff_datetime\" in df.columns:\n",
    "        df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "\n",
    "    # 4. å®šä¹‰è¦å¯¼å…¥çš„åˆ—ï¼Œé¡ºåºå¿…é¡»å’Œ yellow_taxi_clean è¡¨ä¸€è‡´\n",
    "    cols = [\n",
    "        \"vendorid\",\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"ratecodeid\",\n",
    "        \"pulocationid\",\n",
    "        \"dolocationid\",\n",
    "        \"payment_type\",\n",
    "        \"fare_amount\",\n",
    "        \"extra\",\n",
    "        \"mta_tax\",\n",
    "        \"tip_amount\",\n",
    "        \"tolls_amount\",\n",
    "        \"improvement_surcharge\",\n",
    "        \"total_amount\",\n",
    "        \"congestion_surcharge\"\n",
    "    ]\n",
    "\n",
    "    # 5. åªä¿ç•™éœ€è¦çš„åˆ—\n",
    "    copy_df = df[cols].copy()\n",
    "    \n",
    "    # 6. ç¡®ä¿æ•´æ•°åˆ—çš„æ•°æ®ç±»å‹æ­£ç¡®ï¼ˆé¿å… 1.0 è¿™æ ·çš„æµ®ç‚¹è¡¨ç¤ºï¼‰\n",
    "    int_cols = [\"vendorid\", \"passenger_count\", \"ratecodeid\", \"pulocationid\", \"dolocationid\", \"payment_type\"]\n",
    "    for col in int_cols:\n",
    "        if col in copy_df.columns:\n",
    "            # å°†æœ‰æ•ˆå€¼è½¬ä¸ºæ•´æ•°ï¼Œä¿æŒ NaN ä¸å˜\n",
    "            copy_df[col] = copy_df[col].apply(lambda x: int(x) if pd.notna(x) else None)\n",
    "    \n",
    "    # 7. å¤„ç†å…¶ä½™ NaN -> NULL\n",
    "    copy_df = copy_df.where(pd.notnull(copy_df), None)\n",
    "\n",
    "    prep_time = time.time() - start_time - load_time\n",
    "    print(f\"Data prep completed in {prep_time:.1f}s - Rows to insert: {len(copy_df):,}\")\n",
    "\n",
    "    # 8. å†™å…¥å†…å­˜ CSV bufferï¼ˆä¾› COPY ä½¿ç”¨ï¼‰\n",
    "    buffer = io.StringIO()\n",
    "    copy_df.to_csv(buffer, index=False, header=False, na_rep='\\\\N')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    csv_time = time.time() - start_time - load_time - prep_time\n",
    "    print(f\"CSV buffer created in {csv_time:.1f}s\")\n",
    "\n",
    "    # 9. ç”¨ COPY æ‰¹é‡æ’å…¥ PostgreSQL\n",
    "    insert_start = time.time()\n",
    "    conn = psycopg.connect(\n",
    "        host=PG_HOST,\n",
    "        port=PG_PORT,\n",
    "        dbname=PG_DB,\n",
    "        user=PG_USER,\n",
    "        password=PG_PASS\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # ä½¿ç”¨ copy() æ–¹æ³•çš„æ­£ç¡®æ–¹å¼\n",
    "            with cur.copy(f\"COPY yellow_taxi_clean({', '.join(cols)}) FROM STDIN WITH (FORMAT CSV, NULL '\\\\N')\") as copy:\n",
    "                while True:\n",
    "                    data = buffer.read(8192)  # æ¯æ¬¡è¯»å– 8KB\n",
    "                    if not data:\n",
    "                        break\n",
    "                    copy.write(data)\n",
    "        \n",
    "        # æ˜¾å¼æäº¤\n",
    "        conn.commit()\n",
    "        \n",
    "        insert_time = time.time() - insert_start\n",
    "        total_time = time.time() - start_time\n",
    "        rows_per_sec = len(copy_df) / insert_time if insert_time > 0 else 0\n",
    "        \n",
    "        print(f\"âœ… Inserted {len(copy_df):,} rows in {insert_time:.1f}s ({rows_per_sec:,.0f} rows/sec)\")\n",
    "        print(f\"Total time: {total_time:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(f\"âŒ COPY failed: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# ä¸»ç¨‹åº\n",
    "if __name__ == \"__main__\":\n",
    "    # å…ˆåˆ›å»ºè¡¨ï¼ˆå¦‚æœè¿˜æ²¡åˆ›å»ºï¼‰\n",
    "    print(\"=== åˆ›å»ºè¡¨ yellow_taxi_clean ===\")\n",
    "    with psycopg.connect(\n",
    "        host=PG_HOST, \n",
    "        port=PG_PORT, \n",
    "        dbname=PG_DB, \n",
    "        user=PG_USER, \n",
    "        password=PG_PASS, \n",
    "        autocommit=True\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('''\n",
    "                DROP TABLE IF EXISTS yellow_taxi_clean;\n",
    "\n",
    "                CREATE TABLE yellow_taxi_clean (\n",
    "                    VendorID INTEGER,\n",
    "                    tpep_pickup_datetime TIMESTAMP,\n",
    "                    tpep_dropoff_datetime TIMESTAMP,\n",
    "                    passenger_count INTEGER,\n",
    "                    trip_distance NUMERIC,\n",
    "                    RatecodeID INTEGER,\n",
    "                    PULocationID INTEGER,\n",
    "                    DOLocationID INTEGER,\n",
    "                    payment_type INTEGER,\n",
    "                    fare_amount NUMERIC,\n",
    "                    extra NUMERIC,\n",
    "                    mta_tax NUMERIC,\n",
    "                    tip_amount NUMERIC,\n",
    "                    tolls_amount NUMERIC,\n",
    "                    improvement_surcharge NUMERIC,\n",
    "                    total_amount NUMERIC,\n",
    "                    congestion_surcharge NUMERIC\n",
    "                );\n",
    "            ''')\n",
    "    print('âœ… Table yellow_taxi_clean created\\n')\n",
    "    \n",
    "    # å¯¼å…¥æ•°æ® - æµ‹è¯•æ¨¡å¼ï¼šåªå¯¼å…¥10ä¸‡æ¡\n",
    "    print(\"=== å¼€å§‹å¯¼å…¥æ•°æ®ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰===\")\n",
    "    parquet_file = \"yellow_taxi_2022_2025_final_cleaned.parquet\"\n",
    "    load_cleaned_parquet_to_postgres(parquet_file, max_rows=1000000)  # ğŸ‘ˆ é™åˆ¶10ä¸‡è¡Œ\n",
    "    \n",
    "    # éªŒè¯æ•°æ®\n",
    "    print(\"\\n=== éªŒè¯å¯¼å…¥ç»“æœ ===\")\n",
    "    with psycopg.connect(\n",
    "        host=PG_HOST, \n",
    "        port=PG_PORT, \n",
    "        dbname=PG_DB, \n",
    "        user=PG_USER, \n",
    "        password=PG_PASS\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            # æ€»è®°å½•æ•°\n",
    "            cur.execute(\"SELECT COUNT(*) FROM yellow_taxi_clean;\")\n",
    "            count = cur.fetchone()[0]\n",
    "            print(f\"è¡¨ä¸­æ€»è®°å½•æ•°: {count:,}\")\n",
    "            \n",
    "            # æ—¶é—´èŒƒå›´\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    MIN(tpep_pickup_datetime) as earliest,\n",
    "                    MAX(tpep_pickup_datetime) as latest\n",
    "                FROM yellow_taxi_clean;\n",
    "            \"\"\")\n",
    "            date_range = cur.fetchone()\n",
    "            print(f\"æ—¶é—´èŒƒå›´: {date_range[0]} ~ {date_range[1]}\")\n",
    "            \n",
    "            # NULLå€¼ç»Ÿè®¡\n",
    "            cur.execute(\"\"\"\n",
    "                SELECT \n",
    "                    COUNT(*) - COUNT(passenger_count) as null_passenger,\n",
    "                    COUNT(*) - COUNT(trip_distance) as null_distance,\n",
    "                    COUNT(*) - COUNT(fare_amount) as null_fare\n",
    "                FROM yellow_taxi_clean;\n",
    "            \"\"\")\n",
    "            nulls = cur.fetchone()\n",
    "            print(f\"NULLå€¼ç»Ÿè®¡: passenger={nulls[0]}, distance={nulls[1]}, fare={nulls[2]}\")\n",
    "            \n",
    "            # æŸ¥çœ‹å‰5æ¡\n",
    "            cur.execute(\"SELECT * FROM yellow_taxi_clean LIMIT 5;\")\n",
    "            print(\"\\nå‰5æ¡è®°å½•:\")\n",
    "            for row in cur.fetchall():\n",
    "                print(row)\n",
    "    \n",
    "    print(\"\\nâœ… å¯¼å…¥å®Œæˆï¼\")\n",
    "    print(\"\\nğŸ’¡ æç¤º: æµ‹è¯•å®Œæˆåï¼Œå¦‚éœ€å¯¼å…¥å…¨éƒ¨æ•°æ®ï¼Œè¯·å°† max_rows=100000 æ”¹ä¸º max_rows=None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7aff362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“– è¯»å– taxi_zone_lookup.csv...\n",
      "âœ… è¯»å–æˆåŠŸï¼Œå…± 265 æ¡è®°å½•\n",
      "ğŸ“Š åˆ—å: ['LocationID', 'Borough', 'Zone', 'service_zone']\n",
      "\n",
      "å‰ 5 æ¡æ•°æ®:\n",
      "   LocationID        Borough                     Zone service_zone\n",
      "0           1            EWR           Newark Airport          EWR\n",
      "1           2         Queens              Jamaica Bay    Boro Zone\n",
      "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
      "3           4      Manhattan            Alphabet City  Yellow Zone\n",
      "4           5  Staten Island            Arden Heights    Boro Zone\n",
      "\n",
      "============================================================\n",
      "ğŸ—„ï¸  åˆ›å»º taxi_zone_lookup è¡¨...\n",
      "âœ… è¡¨åˆ›å»ºæˆåŠŸ\n",
      "\n",
      "============================================================\n",
      "ğŸ“¥ å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“...\n",
      "ğŸ“ å‡†å¤‡æ’å…¥ 265 æ¡è®°å½•...\n",
      "âœ… æˆåŠŸæ’å…¥ 265 æ¡è®°å½•\n",
      "\n",
      "============================================================\n",
      "ğŸ” éªŒè¯å¯¼å…¥ç»“æœ...\n",
      "âœ… è¡¨ä¸­æ€»è®°å½•æ•°: 265\n",
      "\n",
      "å‰ 5 æ¡è®°å½•:\n",
      "  ID: 1, Borough: EWR, Zone: Newark Airport, Service: EWR\n",
      "  ID: 2, Borough: Queens, Zone: Jamaica Bay, Service: Boro Zone\n",
      "  ID: 3, Borough: Bronx, Zone: Allerton/Pelham Gardens, Service: Boro Zone\n",
      "  ID: 4, Borough: Manhattan, Zone: Alphabet City, Service: Yellow Zone\n",
      "  ID: 5, Borough: Staten Island, Zone: Arden Heights, Service: Boro Zone\n",
      "\n",
      "æŒ‰è¡Œæ”¿åŒºç»Ÿè®¡:\n",
      "  Queens: 69 ä¸ªåŒºåŸŸ\n",
      "  Manhattan: 69 ä¸ªåŒºåŸŸ\n",
      "  Brooklyn: 61 ä¸ªåŒºåŸŸ\n",
      "  Bronx: 43 ä¸ªåŒºåŸŸ\n",
      "  Staten Island: 20 ä¸ªåŒºåŸŸ\n",
      "  EWR: 1 ä¸ªåŒºåŸŸ\n",
      "  NaN: 1 ä¸ªåŒºåŸŸ\n",
      "  Unknown: 1 ä¸ªåŒºåŸŸ\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ å¯¼å…¥å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨è´¹ç”¨è®¡ç®—å™¨äº†ï¼\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import psycopg\n",
    "import pandas as pd\n",
    "\n",
    "# æ•°æ®åº“é…ç½®\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"dbname\": \"taxi\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\"\n",
    "}\n",
    "\n",
    "# 1. è¯»å– CSV æ–‡ä»¶\n",
    "print(\"ğŸ“– è¯»å– taxi_zone_lookup.csv...\")\n",
    "df = pd.read_csv('taxi_zone_lookup.csv')\n",
    "\n",
    "print(f\"âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "print(f\"ğŸ“Š åˆ—å: {list(df.columns)}\")\n",
    "print(\"\\nå‰ 5 æ¡æ•°æ®:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. åˆ›å»ºè¡¨\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ—„ï¸  åˆ›å»º taxi_zone_lookup è¡¨...\")\n",
    "\n",
    "with psycopg.connect(**PG_CONFIG) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # åˆ é™¤æ—§è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "        cur.execute(\"DROP TABLE IF EXISTS taxi_zone_lookup;\")\n",
    "        \n",
    "        # åˆ›å»ºæ–°è¡¨\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE taxi_zone_lookup (\n",
    "                LocationID INTEGER PRIMARY KEY,\n",
    "                Borough VARCHAR(50),\n",
    "                Zone VARCHAR(100),\n",
    "                service_zone VARCHAR(50)\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"âœ… è¡¨åˆ›å»ºæˆåŠŸ\")\n",
    "\n",
    "# 3. å¯¼å…¥æ•°æ®\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¥ å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“...\")\n",
    "\n",
    "# ç»Ÿä¸€åˆ—åï¼ˆå¦‚æœ CSV åˆ—åä¸ä¸€æ ·ï¼‰\n",
    "# é€šå¸¸ CSV å¯èƒ½æ˜¯ LocationID, Borough, Zone, service_zone\n",
    "# æˆ–è€… location_id, borough, zone, service_zone\n",
    "df.columns = df.columns.str.strip()  # å»æ‰ç©ºæ ¼\n",
    "\n",
    "# é‡å‘½ååˆ—ä»¥åŒ¹é…æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "column_mapping = {\n",
    "    'LocationID': 'LocationID',\n",
    "    'location_id': 'LocationID',\n",
    "    'LOCATIONID': 'LocationID',\n",
    "    'Borough': 'Borough',\n",
    "    'borough': 'Borough',\n",
    "    'BOROUGH': 'Borough',\n",
    "    'Zone': 'Zone',\n",
    "    'zone': 'Zone',\n",
    "    'ZONE': 'Zone',\n",
    "    'service_zone': 'service_zone',\n",
    "    'Service_Zone': 'service_zone',\n",
    "    'SERVICE_ZONE': 'service_zone'\n",
    "}\n",
    "\n",
    "# åº”ç”¨åˆ—åæ˜ å°„\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df.columns:\n",
    "        df.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "# ç¡®ä¿åˆ—åæ­£ç¡®\n",
    "expected_cols = ['LocationID', 'Borough', 'Zone', 'service_zone']\n",
    "df = df[expected_cols]\n",
    "\n",
    "print(f\"ğŸ“ å‡†å¤‡æ’å…¥ {len(df)} æ¡è®°å½•...\")\n",
    "\n",
    "# ä½¿ç”¨ executemany æ‰¹é‡æ’å…¥\n",
    "with psycopg.connect(**PG_CONFIG) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # å‡†å¤‡æ’å…¥è¯­å¥\n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO taxi_zone_lookup (LocationID, Borough, Zone, service_zone)\n",
    "            VALUES (%s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        \n",
    "        # è½¬æ¢ä¸ºåˆ—è¡¨\n",
    "        data = df.values.tolist()\n",
    "        \n",
    "        # æ‰¹é‡æ’å…¥\n",
    "        cur.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸæ’å…¥ {len(df)} æ¡è®°å½•\")\n",
    "\n",
    "# 4. éªŒè¯å¯¼å…¥\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” éªŒè¯å¯¼å…¥ç»“æœ...\")\n",
    "\n",
    "with psycopg.connect(**PG_CONFIG) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # æ€»æ•°\n",
    "        cur.execute(\"SELECT COUNT(*) FROM taxi_zone_lookup;\")\n",
    "        count = cur.fetchone()[0]\n",
    "        print(f\"âœ… è¡¨ä¸­æ€»è®°å½•æ•°: {count}\")\n",
    "        \n",
    "        # æŸ¥çœ‹å‰ 5 æ¡\n",
    "        cur.execute(\"SELECT * FROM taxi_zone_lookup ORDER BY LocationID LIMIT 5;\")\n",
    "        print(\"\\nå‰ 5 æ¡è®°å½•:\")\n",
    "        for row in cur.fetchall():\n",
    "            print(f\"  ID: {row[0]}, Borough: {row[1]}, Zone: {row[2]}, Service: {row[3]}\")\n",
    "        \n",
    "        # æŒ‰ Borough ç»Ÿè®¡\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT Borough, COUNT(*) as zone_count \n",
    "            FROM taxi_zone_lookup \n",
    "            GROUP BY Borough \n",
    "            ORDER BY zone_count DESC;\n",
    "        \"\"\")\n",
    "        print(\"\\næŒ‰è¡Œæ”¿åŒºç»Ÿè®¡:\")\n",
    "        for row in cur.fetchall():\n",
    "            print(f\"  {row[0]}: {row[1]} ä¸ªåŒºåŸŸ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ å¯¼å…¥å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨è´¹ç”¨è®¡ç®—å™¨äº†ï¼\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ded3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essexu_ev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
